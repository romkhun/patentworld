#!/usr/bin/env python3
"""
Firm-Level Exploration vs. Exploitation Over Time (Analysis Group 2)

For each of the top 50 assignees, computes per patent:
  - Technology newness (Indicator 1): firm presence in CPC subclass over prior 5 years
  - Citation newness (Indicator 2): share of backward citations to unfamiliar CPC sections
  - External knowledge sourcing (Indicator 3): 1 - self-citation rate
  - Composite exploration score (average of 3 indicators)

Aggregates per (firm × year):
  - Mean exploration score
  - Exploration / exploitation / ambidextrous shares
  - Indicator decomposition
  - Exploration quality premium

Output:
  company/firm_exploration_scores.json
  company/firm_exploration_scatter.json
  company/firm_exploration_trajectories.json
"""
import json
import time
import duckdb
import numpy as np
from config import (
    PATENT_TSV, CPC_CURRENT_TSV, CITATION_TSV, ASSIGNEE_TSV,
    OUTPUT_DIR, save_json, timed_msg,
)

OUT = f"{OUTPUT_DIR}/company"
con = duckdb.connect()

with open(f"{OUT}/company_name_mapping.json", "r") as f:
    COMPANY_MAP = json.load(f)

def clean_name(raw):
    return COMPANY_MAP.get(raw, raw)

# ── Step 1: Identify top 50 assignees ────────────────────────────────────────
timed_msg("Step 1: Identify top 50 assignees")
t0 = time.time()

top50_rows = con.execute(f"""
    SELECT a.disambig_assignee_organization AS org, COUNT(DISTINCT p.patent_id) AS total
    FROM {PATENT_TSV()} p
    JOIN {ASSIGNEE_TSV()} a ON p.patent_id = a.patent_id AND a.assignee_sequence = 0
    WHERE p.patent_type = 'utility'
      AND a.disambig_assignee_organization IS NOT NULL
      AND TRIM(a.disambig_assignee_organization) != ''
    GROUP BY org
    ORDER BY total DESC
    LIMIT 50
""").fetchall()
top50_orgs = [row[0] for row in top50_rows]
org_sql = ','.join(f"'{o.replace(chr(39), chr(39)+chr(39))}'" for o in top50_orgs)
print(f"  Top 50 identified in {time.time()-t0:.1f}s")

# ── Step 2: Build firm patent table ──────────────────────────────────────────
timed_msg("Step 2: Build firm patent table")
t0 = time.time()

con.execute("DROP TABLE IF EXISTS fp2")
con.execute(f"""
    CREATE TEMPORARY TABLE fp2 AS
    SELECT
        p.patent_id,
        YEAR(CAST(p.patent_date AS DATE)) AS year,
        a.disambig_assignee_organization AS org
    FROM {PATENT_TSV()} p
    JOIN {ASSIGNEE_TSV()} a ON p.patent_id = a.patent_id AND a.assignee_sequence = 0
    WHERE p.patent_type = 'utility'
      AND p.patent_date IS NOT NULL
      AND YEAR(CAST(p.patent_date AS DATE)) BETWEEN 1976 AND 2025
      AND a.disambig_assignee_organization IN ({org_sql})
""")
fp_count = con.execute("SELECT COUNT(*) FROM fp2").fetchone()[0]
print(f"  fp2: {fp_count:,} rows in {time.time()-t0:.1f}s")

# ── Step 3: Indicator 1 — Technology Newness ─────────────────────────────────
timed_msg("Step 3: Technology Newness (primary CPC subclass presence in prior 5 years)")
t0 = time.time()

# Get primary CPC subclass per patent
con.execute("DROP TABLE IF EXISTS patent_primary_cpc")
con.execute(f"""
    CREATE TEMPORARY TABLE patent_primary_cpc AS
    SELECT patent_id, cpc_subclass, cpc_section
    FROM {CPC_CURRENT_TSV()}
    WHERE cpc_sequence = 0
""")

# Count firm's prior patents in same CPC subclass (5-year lookback)
con.execute("DROP TABLE IF EXISTS tech_newness")
con.execute("""
    CREATE TEMPORARY TABLE tech_newness AS
    WITH prior_counts AS (
        SELECT
            fp.patent_id,
            fp.org,
            fp.year,
            ppc.cpc_subclass,
            (
                SELECT COUNT(DISTINCT fp2_inner.patent_id)
                FROM fp2 fp2_inner
                JOIN patent_primary_cpc ppc2 ON fp2_inner.patent_id = ppc2.patent_id
                WHERE fp2_inner.org = fp.org
                  AND ppc2.cpc_subclass = ppc.cpc_subclass
                  AND fp2_inner.year BETWEEN fp.year - 5 AND fp.year - 1
            ) AS prior_count
        FROM fp2 fp
        JOIN patent_primary_cpc ppc ON fp.patent_id = ppc.patent_id
        WHERE fp.year >= 1981
    )
    SELECT
        patent_id,
        org,
        year,
        CASE
            WHEN prior_count = 0 THEN 1.0
            WHEN prior_count >= 10 THEN 0.0
            ELSE 1.0 - (CAST(prior_count AS DOUBLE) / 10.0)
        END AS tech_newness
    FROM prior_counts
""")
tn_count = con.execute("SELECT COUNT(*) FROM tech_newness").fetchone()[0]
print(f"  tech_newness: {tn_count:,} rows in {time.time()-t0:.1f}s")

# ── Step 4: Indicator 3 — External Knowledge Sourcing (1 - self-citation) ────
timed_msg("Step 4: External Knowledge Sourcing (inverse self-citation)")
t0 = time.time()

# Build assignee lookup for all patents (for matching)
con.execute("DROP TABLE IF EXISTS all_assignees")
con.execute(f"""
    CREATE TEMPORARY TABLE all_assignees AS
    SELECT patent_id, disambig_assignee_organization AS org
    FROM {ASSIGNEE_TSV()}
    WHERE assignee_sequence = 0
      AND disambig_assignee_organization IS NOT NULL
      AND TRIM(disambig_assignee_organization) != ''
""")

con.execute("DROP TABLE IF EXISTS self_cite_rate")
con.execute(f"""
    CREATE TEMPORARY TABLE self_cite_rate AS
    SELECT
        fp.patent_id,
        fp.org,
        CASE
            WHEN COUNT(c.citation_patent_id) = 0 THEN 0.5
            ELSE 1.0 - (
                CAST(SUM(CASE WHEN aa.org = fp.org THEN 1 ELSE 0 END) AS DOUBLE)
                / COUNT(c.citation_patent_id)
            )
        END AS external_score
    FROM fp2 fp
    LEFT JOIN {CITATION_TSV()} c ON fp.patent_id = c.patent_id
    LEFT JOIN all_assignees aa ON c.citation_patent_id = aa.patent_id
    GROUP BY fp.patent_id, fp.org
""")
sc_count = con.execute("SELECT COUNT(*) FROM self_cite_rate").fetchone()[0]
print(f"  self_cite_rate: {sc_count:,} rows in {time.time()-t0:.1f}s")

# ── Step 5: Indicator 2 — Citation Newness (simplified) ──────────────────────
timed_msg("Step 5: Citation Newness (share of backward cites in unfamiliar CPC sections)")
t0 = time.time()

# Count firm's established CPC sections in prior 5 years
con.execute("DROP TABLE IF EXISTS firm_section_presence")
con.execute("""
    CREATE TEMPORARY TABLE firm_section_presence AS
    SELECT
        fp.org,
        fp.year,
        ppc.cpc_section,
        COUNT(DISTINCT fp.patent_id) AS section_count
    FROM fp2 fp
    JOIN patent_primary_cpc ppc ON fp.patent_id = ppc.patent_id
    GROUP BY fp.org, fp.year, ppc.cpc_section
""")

# For citation newness, compute the share of backward citations pointing to
# CPC sections where the firm has <5 patents in prior 5 years
con.execute("DROP TABLE IF EXISTS citation_newness")
con.execute(f"""
    CREATE TEMPORARY TABLE citation_newness AS
    WITH cite_sections AS (
        SELECT
            fp.patent_id,
            fp.org,
            fp.year,
            ppc.cpc_section AS cited_section
        FROM fp2 fp
        JOIN {CITATION_TSV()} c ON fp.patent_id = c.patent_id
        JOIN patent_primary_cpc ppc ON c.citation_patent_id = ppc.patent_id
        WHERE fp.year >= 1981
    ),
    cite_familiarity AS (
        SELECT
            cs.patent_id,
            cs.org,
            cs.year,
            cs.cited_section,
            COALESCE(
                (SELECT SUM(fsp.section_count)
                 FROM firm_section_presence fsp
                 WHERE fsp.org = cs.org
                   AND fsp.cpc_section = cs.cited_section
                   AND fsp.year BETWEEN cs.year - 5 AND cs.year - 1
                ), 0
            ) AS familiarity_count
        FROM cite_sections cs
    )
    SELECT
        patent_id,
        org,
        CAST(SUM(CASE WHEN familiarity_count < 5 THEN 1 ELSE 0 END) AS DOUBLE)
        / NULLIF(COUNT(*), 0) AS citation_newness
    FROM cite_familiarity
    GROUP BY patent_id, org
""")
cn_count = con.execute("SELECT COUNT(*) FROM citation_newness").fetchone()[0]
print(f"  citation_newness: {cn_count:,} rows in {time.time()-t0:.1f}s")

# ── Step 6: Composite exploration score per patent ───────────────────────────
timed_msg("Step 6: Composite exploration score per patent")
t0 = time.time()

con.execute("DROP TABLE IF EXISTS exploration_scores")
con.execute("""
    CREATE TEMPORARY TABLE exploration_scores AS
    SELECT
        fp.patent_id,
        fp.org,
        fp.year,
        COALESCE(tn.tech_newness, 0.5) AS tech_newness,
        COALESCE(cn.citation_newness, 0.5) AS citation_newness,
        COALESCE(sc.external_score, 0.5) AS external_score,
        (COALESCE(tn.tech_newness, 0.5) + COALESCE(cn.citation_newness, 0.5) + COALESCE(sc.external_score, 0.5)) / 3.0 AS composite_score
    FROM fp2 fp
    LEFT JOIN tech_newness tn ON fp.patent_id = tn.patent_id
    LEFT JOIN citation_newness cn ON fp.patent_id = cn.patent_id
    LEFT JOIN self_cite_rate sc ON fp.patent_id = sc.patent_id
    WHERE fp.year >= 1981
""")
es_count = con.execute("SELECT COUNT(*) FROM exploration_scores").fetchone()[0]
print(f"  exploration_scores: {es_count:,} rows in {time.time()-t0:.1f}s")

# ── Step 7: Aggregate per firm × year ────────────────────────────────────────
timed_msg("Step 7: Aggregate exploration metrics per firm × year")
t0 = time.time()

agg_df = con.execute("""
    SELECT
        org,
        year,
        COUNT(*) AS patent_count,
        ROUND(AVG(composite_score), 4) AS mean_exploration,
        ROUND(AVG(tech_newness), 4) AS mean_tech_newness,
        ROUND(AVG(citation_newness), 4) AS mean_citation_newness,
        ROUND(AVG(external_score), 4) AS mean_external_score,
        ROUND(CAST(SUM(CASE WHEN composite_score > 0.6 THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*), 4) AS exploration_share,
        ROUND(CAST(SUM(CASE WHEN composite_score < 0.4 THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*), 4) AS exploitation_share,
        ROUND(CAST(SUM(CASE WHEN composite_score BETWEEN 0.4 AND 0.6 THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*), 4) AS ambidexterity_share
    FROM exploration_scores
    GROUP BY org, year
    HAVING COUNT(*) >= 10
    ORDER BY org, year
""").fetchdf()
print(f"  Aggregated: {len(agg_df):,} rows in {time.time()-t0:.1f}s")

# System-wide mean exploration per year
system_expl = con.execute("""
    SELECT year, ROUND(AVG(composite_score), 4) AS system_mean
    FROM exploration_scores
    GROUP BY year
    ORDER BY year
""").fetchdf()
system_expl_map = dict(zip(system_expl['year'], system_expl['system_mean']))

# ── Step 8: Exploration quality premium ──────────────────────────────────────
timed_msg("Step 8: Exploration quality premium (citations of exploratory vs exploitative)")
t0 = time.time()

# Forward citations for exploration_scores patents (only up to 2019)
quality_premium_df = con.execute(f"""
    WITH explore_cites AS (
        SELECT
            es.org,
            es.year,
            es.composite_score,
            COALESCE(fc.fwd_cites, 0) AS fwd_cites
        FROM exploration_scores es
        LEFT JOIN (
            SELECT c.citation_patent_id AS patent_id, COUNT(*) AS fwd_cites
            FROM {CITATION_TSV()} c
            JOIN {PATENT_TSV()} citing ON c.patent_id = citing.patent_id
            JOIN {PATENT_TSV()} cited ON c.citation_patent_id = cited.patent_id
            WHERE citing.patent_date IS NOT NULL AND cited.patent_date IS NOT NULL
              AND DATEDIFF('day', CAST(cited.patent_date AS DATE), CAST(citing.patent_date AS DATE)) BETWEEN 0 AND 1826
            GROUP BY c.citation_patent_id
        ) fc ON es.patent_id = fc.patent_id
        WHERE es.year BETWEEN 1981 AND 2019
    )
    SELECT
        org,
        year,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY fwd_cites)
            FILTER (WHERE composite_score > 0.6) AS explore_median_cites,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY fwd_cites)
            FILTER (WHERE composite_score < 0.4) AS exploit_median_cites,
        SUM(CASE WHEN composite_score > 0.6 THEN 1 ELSE 0 END) AS explore_count,
        SUM(CASE WHEN composite_score < 0.4 THEN 1 ELSE 0 END) AS exploit_count
    FROM explore_cites
    GROUP BY org, year
    HAVING SUM(CASE WHEN composite_score > 0.6 THEN 1 ELSE 0 END) >= 5
       AND SUM(CASE WHEN composite_score < 0.4 THEN 1 ELSE 0 END) >= 5
    ORDER BY org, year
""").fetchdf()
print(f"  Quality premium: {len(quality_premium_df):,} rows in {time.time()-t0:.1f}s")

# Build premium map
premium_map = {}
for _, row in quality_premium_df.iterrows():
    explore_med = float(row['explore_median_cites']) if row['explore_median_cites'] is not None else None
    exploit_med = float(row['exploit_median_cites']) if row['exploit_median_cites'] is not None else None
    premium = None
    if explore_med is not None and exploit_med is not None and exploit_med > 0:
        premium = round(explore_med - exploit_med, 2)
    premium_map[(row['org'], int(row['year']))] = {
        'explore_median': round(explore_med, 1) if explore_med is not None else None,
        'exploit_median': round(exploit_med, 1) if exploit_med is not None else None,
        'premium': premium,
    }

# ── Step 9: Build output JSON ────────────────────────────────────────────────
timed_msg("Step 9: Build exploration scores JSON")

firm_exploration = {}
for _, row in agg_df.iterrows():
    org = row['org']
    year = int(row['year'])
    name = clean_name(org)
    if name not in firm_exploration:
        firm_exploration[name] = []

    prem = premium_map.get((org, year), {})
    firm_exploration[name].append({
        'year': year,
        'patent_count': int(row['patent_count']),
        'mean_exploration': float(row['mean_exploration']),
        'mean_tech_newness': float(row['mean_tech_newness']),
        'mean_citation_newness': float(row['mean_citation_newness']),
        'mean_external_score': float(row['mean_external_score']),
        'exploration_share': float(row['exploration_share']),
        'exploitation_share': float(row['exploitation_share']),
        'ambidexterity_share': float(row['ambidexterity_share']),
        'system_mean': float(system_expl_map.get(year, 0)),
        'explore_median_cites': prem.get('explore_median'),
        'exploit_median_cites': prem.get('exploit_median'),
        'quality_premium': prem.get('premium'),
    })

for name in firm_exploration:
    firm_exploration[name].sort(key=lambda d: d['year'])

save_json(firm_exploration, f"{OUT}/firm_exploration_scores.json")

# ── Step 10: Exploration × quality scatter (2010-2019) ────────────────────────
timed_msg("Step 10: Exploration × quality scatter (most recent decade)")
t0 = time.time()

# Primary CPC section per firm
primary_section = con.execute("""
    SELECT
        fp.org,
        ppc.cpc_section AS section,
        COUNT(*) AS cnt,
        ROW_NUMBER() OVER (PARTITION BY fp.org ORDER BY COUNT(*) DESC) AS rn
    FROM fp2 fp
    JOIN patent_primary_cpc ppc ON fp.patent_id = ppc.patent_id
    WHERE fp.year BETWEEN 2010 AND 2019
    GROUP BY fp.org, ppc.cpc_section
""").fetchdf()
primary_section = primary_section[primary_section['rn'] == 1]
ps_map = dict(zip(primary_section['org'], primary_section['section']))

scatter_df = con.execute(f"""
    WITH decade_scores AS (
        SELECT
            es.org,
            es.composite_score,
            COALESCE(fc.fwd_cites, 0) AS fwd_cites
        FROM exploration_scores es
        LEFT JOIN (
            SELECT c.citation_patent_id AS patent_id, COUNT(*) AS fwd_cites
            FROM {CITATION_TSV()} c
            JOIN {PATENT_TSV()} citing ON c.patent_id = citing.patent_id
            JOIN {PATENT_TSV()} cited ON c.citation_patent_id = cited.patent_id
            WHERE citing.patent_date IS NOT NULL AND cited.patent_date IS NOT NULL
              AND DATEDIFF('day', CAST(cited.patent_date AS DATE), CAST(citing.patent_date AS DATE)) BETWEEN 0 AND 1826
            GROUP BY c.citation_patent_id
        ) fc ON es.patent_id = fc.patent_id
        WHERE es.year BETWEEN 2010 AND 2019
    )
    SELECT
        org,
        COUNT(*) AS patent_count,
        ROUND(CAST(SUM(CASE WHEN composite_score > 0.6 THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) * 100, 2) AS exploration_share,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY fwd_cites)
            FILTER (WHERE composite_score > 0.6) AS explore_median,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY fwd_cites)
            FILTER (WHERE composite_score < 0.4) AS exploit_median,
        SUM(CASE WHEN composite_score > 0.6 THEN 1 ELSE 0 END) AS explore_count,
        SUM(CASE WHEN composite_score < 0.4 THEN 1 ELSE 0 END) AS exploit_count
    FROM decade_scores
    GROUP BY org
    HAVING SUM(CASE WHEN composite_score > 0.6 THEN 1 ELSE 0 END) >= 20
       AND SUM(CASE WHEN composite_score < 0.4 THEN 1 ELSE 0 END) >= 20
    ORDER BY exploration_share DESC
""").fetchdf()

expl_scatter = []
for _, row in scatter_df.iterrows():
    org = row['org']
    explore_med = float(row['explore_median']) if row['explore_median'] is not None else 0
    exploit_med = float(row['exploit_median']) if row['exploit_median'] is not None else 0
    premium = explore_med - exploit_med
    expl_scatter.append({
        'company': clean_name(org),
        'exploration_share': float(row['exploration_share']),
        'quality_premium': round(premium, 2),
        'patent_count': int(row['patent_count']),
        'primary_section': ps_map.get(org, 'G'),
    })

save_json(expl_scatter, f"{OUT}/firm_exploration_scatter.json")
print(f"  Exploration scatter: {len(expl_scatter)} firms in {time.time()-t0:.1f}s")

# ── Step 11: Exploration share trajectories (top 20) ─────────────────────────
timed_msg("Step 11: Exploration share trajectories (top 20)")

# Get top 20 by recent exploration share
recent_shares = {}
for _, row in agg_df.iterrows():
    name = clean_name(row['org'])
    year = int(row['year'])
    if year >= 2015:
        if name not in recent_shares:
            recent_shares[name] = []
        recent_shares[name].append(float(row['exploration_share']))

avg_recent = {name: np.mean(vals) for name, vals in recent_shares.items() if len(vals) >= 2}
top20_expl = sorted(avg_recent.items(), key=lambda x: -x[1])[:20]
top20_names = [name for name, _ in top20_expl]

trajectories = {}
for name in top20_names:
    if name in firm_exploration:
        trajectories[name] = [
            {'year': d['year'], 'exploration_share': round(d['exploration_share'] * 100, 2)}
            for d in firm_exploration[name]
        ]

save_json(trajectories, f"{OUT}/firm_exploration_trajectories.json")

# ── Cleanup ──────────────────────────────────────────────────────────────────
con.close()
print("\n=== 42_firm_exploration_exploitation complete ===\n")
